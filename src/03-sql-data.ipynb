{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df54db4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    This is a tutorial on integrating sql to do data analysis in python. Some of the cells bellow are hiddened ( shown as <code>...</code>) and you should try to google the answer first before unhiding them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e76785-cd2d-42d3-9549-5e59505c367b",
   "metadata": {},
   "source": [
    "# Typical workflow for a data analysis problem in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c18603-a1f6-462e-8e2c-145afa939821",
   "metadata": {
    "tags": []
   },
   "source": [
    "General procedure:\n",
    "\n",
    "* Breakdown your problem into components\n",
    "* For each component, identify the input and the required output\n",
    "* Find a good library and the corresponding function to consume the input and produce the output\n",
    "* Sometimes, it is good to spend time to understand the mathematics, the algorithms / data structure, and the design behind the library\n",
    "* Write a bit of Python to prepare the data, pipe the components, add small utilities, improve code reusability, etc.\n",
    "\n",
    "In principle, unless it is super easy, always look for existing libraries before attempting to implement it yourself. You are not writing c++ :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c175b-0f24-4733-9dd4-3148f980d69c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## An example problem\n",
    "We have bibliometric data in our MSSQL server. Let's see how well we can predict the citations of publications from other variables.\n",
    "\n",
    "### Components\n",
    "* Get the data from MSSQL server to python\n",
    "* Regression analysis\n",
    "* Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a818be-edbe-40b3-917e-479e446fc949",
   "metadata": {},
   "source": [
    "#### Let's google: connect to MSSQL server from python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8460b-702f-4d20-98ba-0c179bae8af3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "* pyodbc: https://docs.microsoft.com/en-us/sql/machine-learning/data-exploration/python-dataframe-pandas?view=sql-server-ver15\n",
    "* More than one choice: https://stackoverflow.com/questions/57063181/what-are-the-advantages-and-disadvantages-of-using-pypyodbc-pymssql-and-pyodbc\n",
    "* You know you are going to use pandas anyway, and pandas doc suggests sqlalchemy: https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html\n",
    "* sqlalchemy vs pyodbc: https://www.quora.com/What-is-the-difference-between-PyODBC-and-SQLAlchemy\n",
    "* Execute sql query directly in jupyter notebook: https://towardsdatascience.com/how-to-run-sql-queries-from-a-jupyter-notebook-aaa18e59e7bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9da3d-28b7-457e-9f89-e42ec4b6dba1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Create sql engine to load data into pandas dataframe\n",
    "\n",
    "Import libraries / functions\n",
    "\n",
    "You should have installed `pyodbc` as the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e363a3c-b817-4985-9060-7474dd708eea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b0941-60eb-4909-9df8-a0724de89d59",
   "metadata": {
    "tags": []
   },
   "source": [
    "How to connect to mssql: https://docs.sqlalchemy.org/en/14/core/engines.html\n",
    "\n",
    "Create sql engine by sqlalchemy, change `laikh` to your username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mssql+pyodbc://laikh@P-CWTS-010260\", fast_executemany=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae2833-43f2-4845-89e5-d81e06fa7c0e",
   "metadata": {},
   "source": [
    "It is good to briefly see how the database looks like before getting the data into pandas\n",
    "\n",
    "This is a magic provided by `ipython-sql`, remember to change `laikh` to your username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4182e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%sql mssql+pyodbc://laikh@P-CWTS-010260"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a73999-28e9-47c6-a084-a078fef11ab2",
   "metadata": {},
   "source": [
    "`%%sql` indicates that this cell should be excuted as sql instead of python\n",
    "\n",
    "List all databases in the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbe350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT name \n",
    "FROM master.sys.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74221311-1768-478a-92ee-edeff17d7052",
   "metadata": {},
   "source": [
    "View the top rows from the wos_2013.dbo.pub database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TOP (5) *\n",
    "FROM wos_2113.dbo.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d2475-3646-435f-a317-71348924f6a0",
   "metadata": {},
   "source": [
    "Execute a sql query to load the publication data of a specific cluster into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654332db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM wos_2113..pub\n",
    "INNER JOIN wos_2113_classification..clustering AS c\n",
    "ON c.ut = pub.ut\n",
    "WHERE cluster_id1 = 116\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(sql_query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975d4ba-8622-427c-84fe-0de93dbfdf97",
   "metadata": {},
   "source": [
    "#### Visualizing the data\n",
    "Before doing any analysis, we should try to understand the features of the data by visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe5749-1ebe-4fb5-a63e-f895334172c7",
   "metadata": {},
   "source": [
    "Visualize the number of publication by year, using the simple `plot()` function for pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['pub_year']).size().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82f43c-8289-4bd3-a9c2-5e5f35b58b13",
   "metadata": {},
   "source": [
    "There are many good visualization libaries in Python\n",
    "\n",
    "Here, we use the well-known `seaborn` library, it integrates well with pandas dataframe. You may try to google for other alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990de47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6587da8-5221-4edd-b881-9679def68408",
   "metadata": {},
   "source": [
    "Plot the number of citations versus the year of publication, also visualize the effect of open access: https://seaborn.pydata.org/generated/seaborn.lineplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f320d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df, x=\"pub_year\", y=\"n_cits\", hue=\"is_open_access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68eae84-86b4-4102-b9ea-7c0779eab18c",
   "metadata": {},
   "source": [
    "The labels in x-axis are strange, year should be integer.\n",
    "\n",
    "Therefore, I googled to find ways to turn the labels to integer, and I copied the code from https://stackoverflow.com/questions/30327153/seaborn-pylab-changing-xticks-from-float-to-int?rq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782fe8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=df, x=\"pub_year\", y=\"n_cits\", hue=\"is_open_access\")\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(lambda x, _: int(x)))\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab50fa-f217-4196-9a72-3bc648d47207",
   "metadata": {},
   "source": [
    "It still doesn't look correct, the intervals are not even, so I used different keywords to find this: https://stackoverflow.com/questions/30914462/matplotlib-how-to-force-integer-tick-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=df, x=\"pub_year\", y=\"n_cits\", hue=\"is_open_access\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44319686-2167-4270-80ba-b0a34337ce99",
   "metadata": {},
   "source": [
    "#### Prepare for data analysis: transforming the data / feature engineering\n",
    "\n",
    "You can simply use the data in its original form for regression analysis, but it is often beneficial to transform the data to more representative features based on your knowledge.\n",
    "\n",
    "Here, we want to transform the data to the number of years since the year of publication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58b2d0-9580-4700-a0ca-8e8f256ac195",
   "metadata": {},
   "source": [
    "For such a simple arithmetic, pandas support the `-` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_year_1\"] = 2021 - df[\"pub_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749d93f-c952-49e5-8863-b86f083db6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_year_1\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c686b-629a-4169-b91c-50252614a9af",
   "metadata": {},
   "source": [
    "You may also use the `map` function to achieve exactly the same thing.\n",
    "\n",
    "The `lambda x:` declares a function to transform each element in the series (`df[\"pub_year\"]` is a series) to a new element. Since it can be any single variable function, it is more flexible than the `-` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20933c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_year_2\"] = df[\"pub_year\"].map(lambda x: 2021 - x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8694e70-565f-4e47-8340-28f94c1f8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_year_2\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663525dd-d927-4f0d-8815-566abc28c3fa",
   "metadata": {},
   "source": [
    "You may want your `lambda` function to act on the whole row in the dataframe, such that you can take values in other columns in the function. You can use `apply` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587aa2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_year_3\"] = df.apply(lambda x: 2021 - x[\"pub_year\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f562a1-17a0-4f09-8ed7-56bb1d5576c0",
   "metadata": {},
   "source": [
    "You may prefer defining a function outside of the `lambda` function for better layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_year(x):\n",
    "    return 2021 - x[\"pub_year\"]\n",
    "df[\"num_year_4\"] = df.apply(lambda x: compute_num_year(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb97ce-624f-4ba4-8b1e-ba12dd600ad1",
   "metadata": {},
   "source": [
    "As you can see, all the 4 methods produce the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d66527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"num_year_1\", \"num_year_2\", \"num_year_3\",  \"num_year_4\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d1db7-8d3c-41d3-9e0f-4269c151aaac",
   "metadata": {},
   "source": [
    "The data order is not random, we should shuffle the dataframe, I found this by google: https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04fcbb-f73b-4051-ba7f-4660a739d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3001147-a12d-459e-bbca-b76a7eaf1429",
   "metadata": {},
   "source": [
    "Now, it is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad399103-0add-4a16-8d7c-f3c7b4e4f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"num_year_1\", \"num_year_2\", \"num_year_3\",  \"num_year_4\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f44fc-7795-411f-953d-70e027f65b16",
   "metadata": {},
   "source": [
    "There are always multiple ways to achieve the same goal in Python, one could be \"better\" than the other in terms of performance, but you should always ensure things work first before considering alternative \"better\" methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e85203-94b3-4b27-8c92-daa668cf2726",
   "metadata": {},
   "source": [
    "#### Let's google: regression library in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a379541-2ebc-44c5-adc8-dff24acfd2cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "* scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* statmodels: https://www.statsmodels.org/stable/regression.html\n",
    "* xgboost: https://xgboost.readthedocs.io/en/stable/python/python_intro.html\n",
    "* xgboost vs scikit-learn: https://stats.stackexchange.com/questions/282459/xgboost-vs-python-sklearn-gradient-boosted-trees\n",
    "\n",
    "We choose xgboost, you can see the principle of gradient boosted trees here: https://xgboost.readthedocs.io/en/stable/tutorials/model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111cde9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe838824-b56f-4f75-91f6-6ea0717443de",
   "metadata": {},
   "source": [
    "Separate training set and testing set, we use 80% of the data to train the model.\n",
    "\n",
    "Label the testing dataset as `\"test\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12073a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "test_size = len(df) - train_size\n",
    "df_train, df_test = df[:train_size], df[train_size:len(df)].reset_index(drop=True)\n",
    "df_test[\"data\"] = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9bb7fe-b85d-4a10-aeef-a2c9cff928a9",
   "metadata": {},
   "source": [
    "Dependent variable: number of citations\n",
    "\n",
    "Independent variable: number of years from the year of publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = df_train[[\"num_year_1\"]]\n",
    "y_train_1 = df_train[\"n_cits\"]\n",
    "\n",
    "x_test_1 = df_test[[\"num_year_1\"]]\n",
    "y_test_1 = df_test[\"n_cits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93784b-0d03-477e-afdf-9583cd69529c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Define the model, see https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn for the complete list of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor(tree_method=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edc25b2-b87d-4e48-bc5e-717c17495c30",
   "metadata": {},
   "source": [
    "Fit the data by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43997f-0ceb-4ef0-93ea-0e0f1e4b5d95",
   "metadata": {},
   "source": [
    "Predict the citation by the model from the testing data set\n",
    "\n",
    "Copy the testing dataframe frame, replace the actual number of citation by predicted number of citation, and label it as `\"predicted\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb88758",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = reg.predict(x_test_1)\n",
    "df_pred_1 = df_test.copy()\n",
    "df_pred_1[\"n_cits\"] = y_pred_1\n",
    "df_pred_1[\"data\"] = \"predicted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d7194-801b-4562-a6c9-880500834dc5",
   "metadata": {},
   "source": [
    "To analyze the performance of the model, we can compute the root mean square metric between the actual value and the predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd62860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f85aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms1 = sqrt(mean_squared_error(y_pred_1, y_test_1))\n",
    "print(\"root mean square 1 = \" + str(rms1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c6e96-4a0a-49e2-ad1e-d2fc5d11d1e4",
   "metadata": {},
   "source": [
    "We can also visualize the actual value and the predicted value as a function of the number of years since the year of publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test_1 = pd.concat([df_test, df_pred_1]).reset_index(drop=True)\n",
    "ax = sns.lineplot(data=df_pred_test_1, x=\"num_year_1\", y=\"n_cits\", hue=\"data\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca8faa-aed9-42c6-85c2-49bbd50ac8f0",
   "metadata": {},
   "source": [
    "Let's try once more, but we add `\"is_open_access\"` as an addition independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc861eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = df_train[[\"num_year_1\", \"is_open_access\"]]\n",
    "y_train_2 = df_train[\"n_cits\"]\n",
    "\n",
    "x_test_2 = df_test[[\"num_year_1\", \"is_open_access\"]]\n",
    "y_test_2 = df_test[\"n_cits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b74621",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(x_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = reg.predict(x_test_2)\n",
    "df_pred_2 = df_test.copy()\n",
    "df_pred_2[\"n_cits\"] = y_pred_2\n",
    "df_pred_2[\"data\"] = \"predicted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a21e8-2e59-44af-a9e3-715bc0054945",
   "metadata": {},
   "source": [
    "Adding extra inforation does not necessarily improve the predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bacb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms2 = sqrt(mean_squared_error(y_pred_2, y_test_2))\n",
    "print(\"root mean square 1 = \" + str(rms1))\n",
    "print(\"root mean square 2 = \" + str(rms2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test_2 = pd.concat([df_test, df_pred_2]).reset_index(drop=True)\n",
    "ax = sns.lineplot(data=df_pred_test_2, x=\"num_year_1\", y=\"n_cits\", hue=\"data\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869b1b5-e27f-4e6c-9bed-b609c9453a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd4063e-5afd-4ac6-bb9a-ac06d1b2f31a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the dataframe back to the MSSQL server\n",
    "\n",
    "You may want to save what you get from python back to the sql server.\n",
    "\n",
    "Here, we create a new schema named `practical`, and save the dataframe `df_pred_test_2` as a database named `intro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b0752-42cb-4dc4-8c5c-b10a8c55e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"practical\" not in engine.dialect.get_schema_names(engine):\n",
    "    engine.execute(db.schema.CreateSchema(\"practical\"))\n",
    "    \n",
    "df_pred_test_2.to_sql(\"intro\", con=engine, schema=\"practical\", if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2fa5de-0ead-4115-88fa-d74f0555c05c",
   "metadata": {},
   "source": [
    "And you can now see the database in the sql server, remember to change `laikh` to your username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd6bd2-0331-4440-b7d6-be8dfd5b4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TOP (5) *\n",
    "FROM userdb_laikh.practical.intro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
